{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e783b76b-8eb6-463d-ab47-df991cc54f30",
   "metadata": {},
   "source": [
    "### Table of Contents \n",
    "* [Introduction](#Introduction)\n",
    "* [About the Dataset](#About-the-Dataset)\n",
    "* [SQL Code](#SQL-Code)\n",
    "* [Data Exploration](#Data-Exploration)\n",
    "* [Aggregated Table](#Aggregated-Table)\n",
    "* [Distribution Chart](#Distribution-Chart)\n",
    "* [Chi-Square Test of Independence](#Chi-Square-Test-of-Independence)\n",
    "* [Creating a Contingency Table](#Creating-a-Contingency-Table)\n",
    "* [Chi-Square Test Code](#Chi-Square-Test-Code)\n",
    "* [Chi-Square Test Results](#Chi-Square-Test-Results)\n",
    "* [Conclusion](#Conclusion)\n",
    "\n",
    "## Introduction\n",
    "<div style=\"text-align: justify;\">\n",
    "Welcome to the analysis of the Brazilian e-commerce dataset from Olist Store. This project aims to compare the average number of sales across different rating groups using a one-way ANOVA or Analysis of Variance. ANOVA is a statistical method used to compare the means/average across three or more groups. It examines variability both within each group, and across them to determine statistical significance. <a href=\"https://www.statology.org/understanding-anova-when-and-how-to-use-it-in-your-research/\" target=\"_blank\">Siavoshi, Mehrnaz. \"Understanding ANOVA: When and How to Use It in Your Research.\" Statology. October 18, 2024.</a> We hope to uncover insights that can benefit sellers on the e-commerce platform.\n",
    "<br>\n",
    "<br>\n",
    "    We hypothesize that there are significant differences in the average number of sales across different rating groups. This suggests that the average number of sales is not the same for all rating groups, indicating that the rating groups have an impact on sales performance.<br>\n",
    "</div>\n",
    "\n",
    "## About the Dataset\n",
    " \n",
    "The dataset can be found on <strong>kaggle</strong> <a href=\"https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce\" target=\"_blank\">click here to view the dataset on kaggle</a>\n",
    "\n",
    "This dataset contains public information on orders made at Olist Store, a Brazilian e-commerce platform. It includes details of 100,000 orders from 2016 to 2018 across various marketplaces in Brazil.\n",
    "\n",
    "While this dataset offers a comprehensive view of sales during that period, it does not cover the entire population of all possible sales data. Therefore, it is considered a **sample dataset**.\n",
    "\n",
    "**Hypothesis testing** is essentially a method to determine if the observations from a sample can be generalized to the broader population. It helps to assess whether the patterns or effects seen in the sample data are likely to be true for the entire population or if they could have occurred by random chance.\n",
    "\n",
    "### Accessing the data\n",
    "The dataset consists of 8 csv files. I've imported these files into <a href=\"https://sqlitebrowser.org/\" target=\"_blank\">DB Browser for SQLite</a> to query the data needed for each step and upload the files into my github repository to  be used in jupyter notebooks.\n",
    "\n",
    "Please refer to the data schema below:\n",
    "\n",
    "<img src=\"https://github.com/Mpakong/Marcel_Peter_Kong_Portfolio/blob/main/images/schema.png?raw=true\">\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dca1ec-cbf3-476e-9b7b-3ee9f7a703aa",
   "metadata": {},
   "source": [
    "## SQL Code\n",
    "  \n",
    "```sql\n",
    "  WITH Products_sold_per_seller as (\n",
    "SELECT seller_id, order_id, COUNT(order_id) as products_sold\n",
    "  FROM olist_order_items_dataset\n",
    " GROUP BY seller_id\n",
    ")\n",
    "\n",
    "SELECT seller_id, products_sold, AVG(r.review_score) as ave_review_score\n",
    "  FROM Products_sold_per_seller as p\n",
    "  LEFT JOIN olist_order_reviews_dataset as r\n",
    "    ON p.order_id = r.order_id\n",
    " GROUP BY seller_id\n",
    " ORDER BY products_sold DESC\n",
    " LIMIT 10;\n",
    "```\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc482b5-46d5-4c95-a339-253a33bf46a0",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>seller_id</th>\n",
    "      <th>products_sold</th>\n",
    "      <th>ave_review_score</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>6560211a19b47992c3666cc44a7e94c0</td>\n",
    "      <td>2033</td>\n",
    "      <td>4.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>4a3ca9315b744ce9f8e9374361493884</td>\n",
    "      <td>1987</td>\n",
    "      <td>5.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1f50f920176fa81dab994f9023523100</td>\n",
    "      <td>1931</td>\n",
    "      <td>5.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>cc419e0650a3c5ba77189a1882b7556a</td>\n",
    "      <td>1775</td>\n",
    "      <td>5.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>da8622b14eb17ae2831f4ac5b9dab84a</td>\n",
    "      <td>1551</td>\n",
    "      <td>5.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>955fee9216a65b617aa5c0531780ce60</td>\n",
    "      <td>1499</td>\n",
    "      <td>5.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1025f0e2d44d7041d6cf58b6550e0bfa</td>\n",
    "      <td>1428</td>\n",
    "      <td>5.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>7c67e1448b00f6e969d365cea6b010ab</td>\n",
    "      <td>1364</td>\n",
    "      <td>4.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>ea8482cd71df3c1969d7b9473ff13abc</td>\n",
    "      <td>1203</td>\n",
    "      <td>3.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>7a67c85e85bb2ce8582c35f2203ad736</td>\n",
    "      <td>1171</td>\n",
    "      <td>5.0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e2360f-333d-4116-9499-3e8751ca6b48",
   "metadata": {},
   "source": [
    "```sql\n",
    "CREATE TABLE anova_data AS\n",
    "\n",
    "  WITH Products_sold_per_seller as (\n",
    "SELECT seller_id, order_id, COUNT(order_id) as products_sold\n",
    "  FROM olist_order_items_dataset\n",
    " GROUP BY seller_id\n",
    ")\n",
    "\n",
    "SELECT seller_id, products_sold, AVG(r.review_score) as ave_review_score\n",
    "  FROM Products_sold_per_seller as p\n",
    "  LEFT JOIN olist_order_reviews_dataset as r\n",
    "    ON p.order_id = r.order_id\n",
    " GROUP BY seller_id\n",
    " ORDER BY products_sold DESC\n",
    "```\n",
    "Created a new table using the above query then exported it as a csv file.\n",
    "the csv file is uploaded into my github repository to be used in jupyter notebook as a dataframe for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbe2c8b-ebca-4524-8794-d8143a02fe5f",
   "metadata": {},
   "source": [
    "## Data Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ac03faa-9214-4ded-91c5-ed615c0773a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seller_id</th>\n",
       "      <th>products_sold</th>\n",
       "      <th>ave_review_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6560211a19b47992c3666cc44a7e94c0</td>\n",
       "      <td>2033</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4a3ca9315b744ce9f8e9374361493884</td>\n",
       "      <td>1987</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1f50f920176fa81dab994f9023523100</td>\n",
       "      <td>1931</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cc419e0650a3c5ba77189a1882b7556a</td>\n",
       "      <td>1775</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>da8622b14eb17ae2831f4ac5b9dab84a</td>\n",
       "      <td>1551</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          seller_id  products_sold  ave_review_score\n",
       "0  6560211a19b47992c3666cc44a7e94c0           2033               4.0\n",
       "1  4a3ca9315b744ce9f8e9374361493884           1987               5.0\n",
       "2  1f50f920176fa81dab994f9023523100           1931               5.0\n",
       "3  cc419e0650a3c5ba77189a1882b7556a           1775               5.0\n",
       "4  da8622b14eb17ae2831f4ac5b9dab84a           1551               5.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "olist_data = pd.read_csv(\"https://raw.githubusercontent.com/Mpakong/Marcel-Peter-Kong/refs/heads/main/projects/anova_data.csv\")\n",
    "olist_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185b9f88-8cea-401c-8995-458c8d8a5fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3095 entries, 0 to 3094\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   seller_id         3095 non-null   object \n",
      " 1   products_sold     3095 non-null   int64  \n",
      " 2   ave_review_score  3073 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 72.7+ KB\n"
     ]
    }
   ],
   "source": [
    "olist_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbcbabaf-0fdd-4864-87c8-e120fe3ec1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ave_review_score\n",
       "5.0    1778\n",
       "4.0     512\n",
       "1.0     449\n",
       "3.0     240\n",
       "2.0      91\n",
       "NaN      22\n",
       "4.5       2\n",
       "3.5       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olist_data['ave_review_score'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4956e7c-e592-4d5a-a2b8-33fabc889643",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "\n",
    "Small Group Sizes: The groups with average review scores of 3.5 and 4.5 have very few data points (1 and 2, respectively). ANOVA requires a reasonable number of observations in each group to perform the test reliably.\n",
    "\n",
    "Presence of NaN Values: The presence of NaN values can affect the calculations. We should handle these missing values appropriately before performing the ANOVA test\n",
    "\n",
    "As such, data with Nan, 4.5 and 3.5 will be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1bff196-5388-48d1-80bf-6bbdb23a870d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ave_review_score\n",
       "5.0    1778\n",
       "4.0     512\n",
       "1.0     449\n",
       "3.0     240\n",
       "2.0      91\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olist_data = olist_data[olist_data['ave_review_score'].notna()] \n",
    "olist_data = olist_data[~olist_data['ave_review_score'].isin([4.5, 3.5])]\n",
    "olist_data['ave_review_score'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b481bd0c-89f2-4cc8-b626-55cc14a9042e",
   "metadata": {},
   "source": [
    "## Group by average review score\n",
    "\n",
    "group the data by the average review score and create lists of products sold for each review score group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc581f05-1f58-48d5-9efe-a2f004b9baa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2033, 1364, 1156,  430,  430,  405,  363,  339,  331,  259,  255,\n",
       "         228,  225,  211,  202,  194,  188,  186,  181,  178,  175,  172,\n",
       "         167,  162,  157,  156,  149,  146,  143,  143,  140,  135,  131,\n",
       "         130,  128,  128,  126,  125,  121,  118,  118,  110,  110,  109,\n",
       "         100,  100,  100,   99,   97,   96,   95,   95,   95,   88,   86,\n",
       "          84,   84,   84,   81,   78,   78,   77,   76,   75,   75,   74,\n",
       "          73,   73,   73,   69,   68,   67,   63,   61,   61,   58,   57,\n",
       "          55,   55,   54,   53,   51,   48,   47,   47,   46,   45,   43,\n",
       "          43,   42,   42,   41,   41,   41,   39,   39,   38,   38,   38,\n",
       "          38,   36,   36,   36,   36,   35,   34,   33,   33,   32,   32,\n",
       "          32,   32,   32,   31,   30,   30,   30,   30,   30,   30,   30,\n",
       "          30,   29,   29,   29,   28,   28,   28,   28,   28,   27,   27,\n",
       "          27,   26,   26,   26,   25,   24,   24,   24,   23,   23,   23,\n",
       "          23,   23,   23,   23,   23,   23,   22,   22,   22,   22,   21,\n",
       "          21,   21,   21,   21,   20,   20,   20,   19,   19,   18,   18,\n",
       "          18,   18,   18,   18,   18,   18,   17,   17,   17,   17,   17,\n",
       "          17,   16,   16,   16,   16,   16,   16,   15,   15,   15,   15,\n",
       "          14,   14,   14,   14,   14,   14,   14,   14,   14,   14,   13,\n",
       "          13,   13,   13,   13,   13,   13,   12,   12,   12,   12,   12,\n",
       "          12,   12,   12,   12,   12,   12,   11,   11,   11,   11,   11,\n",
       "          11,   11,   11,   11,   11,   11,   11,   11,   11,   11,   11,\n",
       "          10,   10,   10,   10,   10,   10,   10,   10,   10,   10,   10,\n",
       "          10,   10,   10,    9,    9,    9,    9,    9,    9,    9,    9,\n",
       "           9,    9,    9,    9,    9,    9,    8,    8,    8,    8,    8,\n",
       "           8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
       "           8,    8,    8,    7,    7,    7,    7,    7,    7,    7,    7,\n",
       "           7,    7,    7,    7,    7,    7,    7,    7,    7,    7,    7,\n",
       "           7,    6,    6,    6,    6,    6,    6,    6,    6,    6,    6,\n",
       "           6,    6,    6,    6,    6,    6,    6,    6,    6,    5,    5,\n",
       "           5,    5,    5,    5,    5,    5,    5,    5,    5,    5,    5,\n",
       "           5,    5,    5,    5,    5,    5,    5,    5,    5,    5,    4,\n",
       "           4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
       "           4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    3,\n",
       "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "           3,    3,    3,    3,    3,    2,    2,    2,    2,    2,    2,\n",
       "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "           2,    2,    2,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1], dtype=int64),\n",
       " array([1987, 1931, 1775, ...,    1,    1,    1], dtype=int64),\n",
       " array([1203,  631,  558,  429,  373,  269,  240,  220,  212,  207,  174,\n",
       "         165,  160,  130,  130,  115,  108,  106,   94,   86,   86,   85,\n",
       "          84,   83,   82,   71,   67,   60,   59,   55,   54,   53,   53,\n",
       "          53,   52,   50,   49,   49,   48,   47,   46,   45,   43,   42,\n",
       "          40,   39,   39,   39,   38,   38,   38,   36,   36,   35,   33,\n",
       "          33,   32,   31,   27,   27,   26,   26,   25,   25,   25,   24,\n",
       "          22,   22,   22,   22,   22,   21,   19,   19,   18,   18,   17,\n",
       "          17,   16,   16,   16,   16,   16,   16,   15,   15,   15,   15,\n",
       "          14,   13,   13,   13,   13,   12,   12,   12,   12,   12,   12,\n",
       "          11,   11,   11,   11,   11,   11,   11,   10,   10,   10,   10,\n",
       "          10,   10,   10,   10,    9,    9,    9,    9,    8,    8,    8,\n",
       "           8,    7,    7,    7,    7,    7,    6,    6,    6,    6,    6,\n",
       "           6,    6,    5,    5,    5,    5,    5,    5,    5,    5,    5,\n",
       "           5,    5,    5,    4,    4,    4,    4,    4,    4,    4,    4,\n",
       "           4,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "           3,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "           2,    2,    2,    2,    2,    2,    2,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1], dtype=int64),\n",
       " array([454, 429, 410, 328, 306, 270, 269, 263, 230, 216, 210, 184, 183,\n",
       "        181, 180, 168, 155, 148, 144, 142, 133, 128, 117, 114, 112, 112,\n",
       "        106,  99,  91,  91,  90,  88,  80,  78,  74,  74,  72,  67,  67,\n",
       "         66,  65,  63,  62,  57,  57,  57,  56,  55,  53,  50,  50,  46,\n",
       "         46,  45,  45,  45,  43,  43,  43,  43,  42,  42,  41,  41,  39,\n",
       "         38,  37,  34,  33,  32,  31,  30,  30,  29,  29,  29,  29,  28,\n",
       "         27,  27,  26,  26,  26,  25,  24,  24,  23,  23,  23,  23,  23,\n",
       "         22,  22,  22,  22,  22,  21,  21,  20,  20,  20,  19,  19,  19,\n",
       "         19,  17,  17,  17,  17,  17,  16,  16,  16,  16,  16,  16,  15,\n",
       "         15,  15,  15,  15,  15,  14,  14,  14,  14,  14,  13,  13,  13,\n",
       "         13,  13,  13,  13,  12,  12,  12,  12,  12,  12,  12,  12,  11,\n",
       "         11,  11,  11,  11,  11,  11,  11,  10,  10,  10,  10,  10,  10,\n",
       "          9,   9,   9,   9,   9,   9,   9,   8,   8,   8,   8,   8,   8,\n",
       "          8,   8,   8,   8,   8,   8,   7,   7,   7,   7,   7,   7,   7,\n",
       "          7,   7,   7,   7,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
       "          6,   6,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
       "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   4,   4,\n",
       "          4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n",
       "          4,   4,   4,   4,   4,   4,   4,   3,   3,   3,   3,   3,   3,\n",
       "          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,\n",
       "          3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,\n",
       "          3,   3,   3,   3,   3,   3,   3,   3,   3,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1], dtype=int64),\n",
       " array([389, 268, 240, 234, 219, 146, 129, 119, 111,  95,  82,  64,  61,\n",
       "         61,  51,  48,  43,  42,  35,  31,  25,  25,  22,  21,  21,  21,\n",
       "         20,  20,  20,  19,  17,  17,  17,  16,  15,  15,  14,  13,  13,\n",
       "         12,  11,  11,  11,  11,  10,   9,   8,   8,   8,   8,   8,   7,\n",
       "          7,   6,   6,   5,   5,   5,   5,   3,   3,   3,   3,   3,   3,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   1,   1,   1,\n",
       "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n",
       "       dtype=int64)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique review scores\n",
    "unique_scores = olist_data['ave_review_score'].unique()\n",
    "\n",
    "# Initialize an empty list to store the groups\n",
    "groups = []\n",
    "\n",
    "# Iterate over each unique review score\n",
    "for score in unique_scores:\n",
    "    # Filter the DataFrame for the current review score\n",
    "    filtered_df = olist_data[olist_data['ave_review_score'] == score]\n",
    "    \n",
    "    # Get the 'products_sold' values for the current review score\n",
    "    products_sold_values = filtered_df['products_sold'].values\n",
    "    \n",
    "    # Append the values to the groups list\n",
    "    groups.append(products_sold_values)\n",
    "\n",
    "# Now 'groups' contains the products_sold values for each unique review score\n",
    "groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0400b58-4acf-48e6-a076-3cc4f7f8cf17",
   "metadata": {},
   "source": [
    "## ANOVA (Analysis of Variance)\n",
    "<div style=\"text-align: justify;\">\n",
    "A one-way ANOVA (Analysis of Variance) test is a statistical method used to compare the means of three or more independent groups to determine if there are significant differences between them. It examines the variability both within each group and across the groups to assess whether the observed differences in means are statistically significant.<br>\n",
    "<br>\n",
    "Key points of One-Way ANOVA:\n",
    "\n",
    "- Dependent Variable: Number of Products Sold\n",
    "- Independent Variable: Average Review Score\n",
    "- Purpose: To determine if there are significant differences in the means of three or more groups.\n",
    "- Groups: The groups being compared should be independent of each other.\n",
    "- Variability: ANOVA analyzes the variability within each group and between the groups.\n",
    "- F-statistic: The test calculates an F-statistic, which is the ratio of the variance between the groups to the variance within the groups.\n",
    "- P-value: The p-value indicates the probability that the observed differences are due to chance. A low p-value (typically < 0.05) suggests that the differences are statistically significant.\n",
    "\n",
    "\n",
    "**Null Hypothesis**: The means of the number of products sold are equal across all rating groups.\n",
    "\n",
    "**Alternate Hypothesis**: There are significant differences in the average number of products sold across different rating groups.\n",
    "\n",
    "\n",
    "In hypothesis testing, the null hypothesis is what we aim to test against.If our ANOVA test results show a significant difference in the average number of products sold across different rating groups (as indicated by a low p-value), we can reject the null hypothesis in favor of the alternative hypothesis. If the results are not significant, we fail to reject the null hypothesis, meaning there is not enough evidence to support the alternative hypothesis.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e9f319-f830-4129-b55b-2f3c22d47021",
   "metadata": {},
   "source": [
    "## stats.f_oneway function\n",
    "\n",
    "The stats.f_oneway function from the scipy.stats library is designed to perform a one-way ANOVA test and it accepts multiple arrays (or sequences) as input. Each array represents a group of data. The function compares the means of these groups to determine if there are significant differences between them.\n",
    "\n",
    "Here's a more detailed explanation:\n",
    "\n",
    "**Input**: The function accepts multiple arrays (or sequences) as input. Each array should contain the data for one group. The arrays can be passed as separate arguments or as a list of arrays. This would be our **groups** variable: contains the products_sold values for each unique review score\n",
    "\n",
    "**Output**: The function returns the **F-statistic** and the **p-value**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5d32d1-a8ac-4d5c-919d-fa18ca891b7c",
   "metadata": {},
   "source": [
    "## ANOVA (Analysis of Variance) Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dddc6b6-cb50-417d-878f-ddd83d632268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 1.662593769694895\n",
      "P-value: 0.1558602230880345\n",
      "Critical value: 2.3748315207903206\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Perform ANOVA test\n",
    "f_statistic, p_value = stats.f_oneway(*groups)\n",
    "print(f'F-statistic: {f_statistic}')\n",
    "print(f'P-value: {p_value}')\n",
    "\n",
    "# Calculate degrees of freedom\n",
    "df_between = len(groups) - 1\n",
    "df_within = olist_data.shape[0] - len(groups)\n",
    "\n",
    "# Determine the critical value\n",
    "alpha = 0.05\n",
    "critical_value = stats.f.ppf(1 - alpha, df_between, df_within)\n",
    "print(f'Critical value: {critical_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a610d76c-a2b0-4cf5-89d1-fc53b49d66fd",
   "metadata": {},
   "source": [
    "## One-Way ANOVA Test Results\n",
    "\n",
    "The F-statistic (1.662593769694895) is less than the critical value (2.3748315207903206), so we fail to reject the null hypothesis.\n",
    "\n",
    "The p-value (0.1558602230880345) is greater than 0.05, so we also fail to reject the null hypothesis.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Both the F-statistic and the p-value indicate that there is not enough evidence to suggest significant differences in the average number of products sold across the different rating groups.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
